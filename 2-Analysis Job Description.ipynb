{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import re, codecs, string, nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import *\n",
    "from pyPdf import PdfFileReader\n",
    "\n",
    "#In this function, I read the resume file. I expect it to be a PDF version. \n",
    "#Further read the text content line by line. Check for unicode characters\n",
    "#I was getting some unicode character encoding error, so used ascii ignore\n",
    "def readMyResume(pdf_file_path, isJDFile):\n",
    "    with open(pdf_file_path) as f:\n",
    "        pdf_reader = PdfFileReader(f)\n",
    "        content = \"\\n\".join(page.extractText().strip() for page in pdf_reader.pages)\n",
    "        content = ' '.join(content.split())        \n",
    "        content = content.encode('ascii', 'ignore')\n",
    "        content = unicode(content.strip(codecs.BOM_UTF8), 'utf-8')\n",
    "    return cleanText(content, isJDFile)\n",
    "\n",
    "#Here, I read the job description file. I expect it to be in .txt format.\n",
    "#Same steps that I did while reading resume file\n",
    "def readJobDescription(jobDescription_file_path, isJDFile):\n",
    "    with open(jobDescription_file_path) as f:\n",
    "        jobDescription = ' '.join(line.strip() for line in f)\n",
    "    jobDescription = unicode(jobDescription.strip(codecs.BOM_UTF8), 'utf-8')\n",
    "    jobDescription = jobDescription.encode('ascii', 'ignore')\n",
    "    return cleanText(jobDescription, isJDFile)\n",
    "    \n",
    "#This is the function where I do the basic text cleaning    \n",
    "def cleanText(text, isJDFile):\n",
    "    #convert text to lowercase\n",
    "    cleanedStr = str(text).lower()\n",
    "    #Remove web addresses\n",
    "    cleanedStr = re.sub(r'(http://\\S*)', '', cleanedStr)\n",
    "    cleanedStr = re.sub(r'(https://\\S*)', '', cleanedStr)\n",
    "    #Remove email addresses\n",
    "    cleanedStr = re.sub('([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\\S*)', '', cleanedStr)\n",
    "    #Some words have slashes which need to be cleaned\n",
    "    cleanedStr = re.sub('/', ' ', cleanedStr)\n",
    "    cleanedStr = re.sub(';', ' ', cleanedStr)\n",
    "    cleanedStr = re.sub(':', ' ', cleanedStr)\n",
    "    cleanedStr = re.sub('\\.', ' ', cleanedStr)\n",
    "    cleanedStr = re.sub(',', ' ', cleanedStr)\n",
    "    cleanedStr = re.sub('-', ' ', cleanedStr)\n",
    "    #Remove punctuations\n",
    "    exclude = set(string.punctuation)\n",
    "    cleanedStr = ''.join(ch for ch in cleanedStr if ch not in exclude)\n",
    "    #Remove numbers/digits\n",
    "    cleanedStr = re.sub('\\d', '', cleanedStr)\n",
    "    #go to stemming and stop word removal function\n",
    "    return stemAndRemoveStopWords(cleanedStr, isJDFile)\n",
    "\n",
    "#This function removes first removes the stop words, then lemmatizes and stems a word\n",
    "#I am using Lancaster Stemmer for stemming and WordNetTokenizer for lemmatization\n",
    "def stemAndRemoveStopWords(txtstr, isJDFile):\n",
    "    stemmedWordsDict = {}\n",
    "    tokens = txtstr.split()\n",
    "    stopWordsList = []\n",
    "    stopWordsList = [line.strip() for line in open(\"stopWords.txt\", 'r')]\n",
    "    cleanStr = \"\"\n",
    "    for t in tokens:\n",
    "        if t in stopWordsList or len(t)<=1:\n",
    "            continue\n",
    "        else:\n",
    "            cleanStr = cleanStr + \" \" + t\n",
    "    cleanStr = cleanStr.strip()\n",
    "\n",
    "    #Using lemmatization\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    cleanedStr = \" \".join([lemma.lemmatize(s) for s in cleanStr.split(\" \") ] )  \n",
    "    \n",
    "   #using stemming\n",
    "    #cleanedStr = \" \".join([PorterStemmer().stem(s) for s in cleanedStr.split(\" \")]) \n",
    "    #cleanedStr = \" \".join([SnowballStemmer(\"porter\").stem(s) for s in cleanedStr.split(\" \")])  \n",
    "    cleanedStr = \" \".join([LancasterStemmer().stem(s) for s in cleanedStr.split(\" \")])  \n",
    "    #cleanedStr=cleanStr\n",
    "    if isJDFile == 'Y':\n",
    "        for s in cleanStr.split(\" \"):\n",
    "            stemmedWordsDict[PorterStemmer().stem(s)] =  s\n",
    "        return cleanedStr, stemmedWordsDict\n",
    "    else:\n",
    "        return cleanedStr\n",
    "\n",
    "#This function calculates the percent match pf resume and job description considering matched words\n",
    "def calculatePercentMatch(resumeContent, jobDescription, stemmedWordsDict):\n",
    "    #Initializing all lists used in this function\n",
    "    resumeText = [] \n",
    "    jdText = []\n",
    "    matchedString = []\n",
    "    matchedList = []\n",
    "    unMatchedList = []\n",
    "\n",
    "    #Tokenize resume content and append to list\n",
    "    for word in resumeContent.split():\n",
    "        if not word in resumeText:\n",
    "            resumeText.append(word)\n",
    "    #Tokenize job description content and append to list\n",
    "    for word in jobDescription.split():\n",
    "        if not word in jdText:\n",
    "            jdText.append(word)\n",
    "    #Match the content in both lists        \n",
    "    for val in jdText:\n",
    "        #if match exists, append to matched list and show original for stemmed word\n",
    "        if val in resumeText:\n",
    "            matchedString.append(str(val))\n",
    "            for key, value in stemmedWordsDict.items():\n",
    "                if key == val:\n",
    "                    matchedList.append(value)\n",
    "        #if match does not exist, append to unMatched list and show original for stemmed word\n",
    "        else:\n",
    "            for key, value in stemmedWordsDict.items():\n",
    "                if key == val:\n",
    "                    unMatchedList.append(value)\n",
    "\n",
    "    #Calculate the percentage match \n",
    "    percentMatch = (len(matchedString)/len(jdText))*100\n",
    "    print '\\n'\n",
    "    print \"There is a %f percent match in your resume and the job description\" %percentMatch\n",
    "    print '\\n'\n",
    "    print \"The matched words in your resume are:\"\n",
    "    print matchedList\n",
    "    print '\\n'\n",
    "    if(percentMatch < 70):\n",
    "        print \"You may want to add a few terms from these into your resume to improve the match\"\n",
    "        print unMatchedList\n",
    "    \n",
    "    return percentMatch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There is a 25.555556 percent match in your resume and the job description\n",
      "\n",
      "\n",
      "The matched words in your resume are:\n",
      "['works', 'internal', 'program', 'interested', 'team', 'group', 'responsibilities', 'design', 'projects', 'excellent', 'environment', 'helpful']\n",
      "\n",
      "\n",
      "You may want to add a few terms from these into your resume to improve the match\n",
      "['enrich', 'classroom', 'learning', 'participating', 'powerschool', 'looking', 'math', 'opportunity', 'integrations', 'ceo', 'admin', 'gain', 'invaluable', 'systems', 'datasets', 'complete', 'record', 'reporting', 'consolidation', 'information', 'tasks', 'search', 'process', 'automate', 'defects', 'cleanup', 'tools', 'control', 'customer', 'web', 'wysiwyg', 'non', 'able', 'workload', 'across', 'multiple', 'strict', 'detail', 'switch', 'gears', 'changing', 'salesforce', 'required']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.555555555555554"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file_path = \"/Users/Ken/Desktop/CA Resume/temp.pdf\"\n",
    "resumeContent = readMyResume(pdf_file_path, isJDFile = 'N')\n",
    "jobDescription_file_path = \"/Users/Ken/Desktop/Job Finder/JobDescription.txt\"\n",
    "jobDescription, stemmedWordsDict = readJobDescription(jobDescription_file_path, isJDFile = 'Y')\n",
    "calculatePercentMatch(resumeContent, jobDescription, stemmedWordsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for resume file\n",
    "pdf_file_path = \"Resume_FileName.pdf\"\n",
    "#path for job description file\n",
    "jobDescription_file_path = \"JobDescription.txt\"\n",
    "#read resume file\n",
    "resumeContent = readMyResume(pdf_file_path, isJDFile = 'N')\n",
    "#read job description file    \n",
    "jobDescription, stemmedWordsDict = readJobDescription(jobDescription_file_path, isJDFile = 'Y')\n",
    "#Calculate the percentage match \n",
    "calculatePercentMatch(resumeContent, jobDescription, stemmedWordsDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
